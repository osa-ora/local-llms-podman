# Deploy LLMs on your local machine 
---

We will explore different ways to download and chat with LLMs on your local machine.

1. Using Ollama: Check: ðŸ”— https://github.com/osa-ora/local-llms-podman/tree/main/ollama
2. Using Podman Desktop Compose and Bee Agent Stack: check: ðŸ”— https://github.com/osa-ora/local-llms-podman/tree/main/bee-agent
3. Using Podman Desktop and AI Lab plugin: Check: ðŸ”— https://github.com/osa-ora/local-llms-podman/tree/main/podman-ai-lab

---
